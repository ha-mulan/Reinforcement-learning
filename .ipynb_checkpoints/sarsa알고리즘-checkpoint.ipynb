{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 구현에 사용할 패키지 임포트하기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 초기 상태의 미로 모습\n",
    "\n",
    "# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 상태를 의미하는 문자열(S0~S8) 표시\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 그림을 그릴 범위 및 눈금 제거 설정\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# S0에 녹색 원으로 현재 위치를 표시\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)\n",
    "\n",
    "# 정책을 결정하는 파라미터의 초깃값 theta_0를 설정\n",
    "\n",
    "# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다.\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a,b)=theta_0.shape\n",
    "Q=np.random.rand(a,b)*theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[       nan 0.63183488 0.05997279        nan]\n",
      " [       nan 0.22109982        nan 0.45809415]\n",
      " [       nan        nan 0.94867197 0.59421799]\n",
      " [0.23012802 0.5008417  0.85103063        nan]\n",
      " [       nan        nan 0.92749831 0.67220994]\n",
      " [0.42059602        nan        nan        nan]\n",
      " [0.66260362        nan        nan        nan]\n",
      " [0.48661723 0.74681796        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_convert_pi_from_theta(theta):\n",
    "    m,n=theta.shape\n",
    "    pi=np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        pi[i][:]=theta[i][:]/np.nansum(theta[i][:])\n",
    "    pi=np.nan_to_num(pi)\n",
    "    return pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sarsa(s,a,r,s_next,a_next,Q,eta,gamma):\n",
    "    if s_next==8:\n",
    "        Q[s,a]=Q[s,a]+eta*(r-Q[s,a])\n",
    "    else :\n",
    "        Q[s,a]=Q[s,a]+eta*(r+gamma*Q[s_next,a_next]-Q[s,a])\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(s,Q,epsilon,pi_0):\n",
    "    direction=[\"up\",\"right\",\"down\",\"left\"]\n",
    "    if np.random.rand()<epsilon:\n",
    "        next_direction=np.random.choice(direction,p=pi_0[s,:])\n",
    "    else:\n",
    "        next_direction=direction[np.nanargmax(Q[s,:])]\n",
    "    \n",
    "    if next_direction == \"up\":\n",
    "        action=0\n",
    "    elif next_direction == \"right\":\n",
    "        action=1\n",
    "    elif next_direction == \"down\":\n",
    "        action=2\n",
    "    elif next_direction == \"left\":\n",
    "        action=3\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_next(s,a,Q,epsilion,pi_0):\n",
    "    direction=[\"up\",\"right\",\"down\",\"left\"]\n",
    "    next_direction=direction[a]\n",
    "    if next_direction == \"up\":\n",
    "        s_next=s-3\n",
    "    elif next_direction == \"right\":\n",
    "        s_next=s+1\n",
    "    elif next_direction == \"down\":\n",
    "        s_next=s+3\n",
    "    elif next_direction == \"left\":\n",
    "        s_next=s-1\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]]  # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "\n",
    "    while (1):  # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next  # 행동 결정\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)을 히스토리에 추가\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 다음 단계의 상태를 구함\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다\n",
    "\n",
    "        # 보상을 부여하고 다음 행동을 계산함\n",
    "        if s_next == 8:\n",
    "            r = 1  # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 다음 행동 a_next를 계산\n",
    "\n",
    "        # 가치함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8:  # 목표 지점에 도달하면 종료\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드: 1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 's_next' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-875bd88f2470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0ms_a_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_maze_ret_s_a_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 상태가치의 변화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-44441052ca12>\u001b[0m in \u001b[0;36mgoal_maze_ret_s_a_Q\u001b[0;34m(Q, epsilon, eta, gamma, pi)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# 현재 상태(마지막이므로 인덱스가 -1)을 히스토리에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0ms_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_s_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# 다음 단계의 상태를 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-e164713dc93a>\u001b[0m in \u001b[0;36mget_s_next\u001b[0;34m(s, a, Q, epsilion, pi_0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnext_direction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0ms_next_direction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ms_next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 's_next' referenced before assignment"
     ]
    }
   ],
   "source": [
    "eta = 0.1  # 학습률\n",
    "gamma = 0.9  # 시간할인율\n",
    "epsilon = 0.5  # ε-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis=1)  # 각 상태마다 가치의 최댓값을 계산\n",
    "is_continue = True\n",
    "episode = 1\n",
    "pi_0=simple_convert_pi_from_theta(theta_0)\n",
    "while is_continue:  # is_continue의 값이 False가 될 때까지 반복\n",
    "    print(\"에피소드: \" + str(episode))\n",
    "\n",
    "    # ε 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis=1)  # 각 상태마다 행동가치의 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v)))  # 상태가치 함수의 변화를 출력\n",
    "    v = new_v\n",
    "\n",
    "    print(\"목표 지점에 이르기까지 걸린 단계 수는 \" + str(len(s_a_history) - 1) + \"단계입니다\")\n",
    "\n",
    "    # 100 에피소드 반복\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
